{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tarfile.open(r'<path>', 'r:gz') as tar:\n",
    "#     tar.list()\n",
    "#     tar.extractall(path='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load & Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_file, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load image labels\n",
    "        mat = scipy.io.loadmat(label_file)\n",
    "        self.labels = mat['labels'].flatten() - 1 # converts 1-based idx in matlab to 0-based idx in python\n",
    "        \n",
    "        # Load image file names\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "        self.image_files.sort()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_file[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_size, image_size)), # resize image to (image_size x image_size)\n",
    "        transforms.ToTensor(), # convert arrays to tensors\n",
    "        transforms.Normalize([.5, .5, .5], [.5, .5, .5]), # normalize pixels (pixel - mean) / STD -> mean & SD for R,G,B is 0.5\n",
    "    ]\n",
    ")\n",
    "\n",
    "img_dir = \"./data/jpg\"\n",
    "label_file = \"imagelabels.mat\"\n",
    "\n",
    "dataset = FlowerDataset(img_dir, label_file, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Define Conditional GAN models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, label_dim, num_classes):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, label_dim) # create embedding layer to map label indices (102 different flowers)\n",
    "        self.model = nn.Sequential( # focus on linear layers only first\n",
    "            nn.Linear(latent_dim + label_dim, 256), # input to CondGenerator is noise & label, 256 output\n",
    "            nn.ReLU(), # introduce non-linearity\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, image_size * image_size), # output is 64 x 64 vector\n",
    "            nn.Tanh() # good practice to add at end to further normalize inputs\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise, labels):\n",
    "        label_emb = self.label_embedding(labels) # map label indices (102 different flowers) by passing to embedding layer\n",
    "        generator_input = torch.cat((noise, label_emb), -1)  # concat tensors, -1 means combine by col to prep input\n",
    "        img = self.model(generator_input)\n",
    "        img = img.view(img.size(0), 3, image_size, image_size) # reshape to (batchsize, RGB, image_size, image_size) (64, 3, 64, 64)\n",
    "        return img\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

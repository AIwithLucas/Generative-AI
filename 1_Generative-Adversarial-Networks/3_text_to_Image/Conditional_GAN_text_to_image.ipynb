{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tarfile.open(r'<path>', 'r:gz') as tar:\n",
    "#     tar.list()\n",
    "#     tar.extractall(path='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load & Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_file, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load image labels\n",
    "        mat = scipy.io.loadmat(label_file)\n",
    "        self.labels = mat['labels'].flatten() - 1 # converts 1-based idx in matlab to 0-based idx in python\n",
    "        \n",
    "        # Load image file names\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "        self.image_files.sort()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_file[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_size, image_size)), # resize image to (image_size x image_size)\n",
    "        transforms.ToTensor(), # convert arrays to tensors\n",
    "        transforms.Normalize([.5, .5, .5], [.5, .5, .5]), # normalize pixels (pixel - mean) / STD -> mean & SD for R,G,B is 0.5\n",
    "    ]\n",
    ")\n",
    "\n",
    "img_dir = \"./data/jpg\"\n",
    "label_file = \"imagelabels.mat\"\n",
    "\n",
    "dataset = FlowerDataset(img_dir, label_file, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
